{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Name: **Shashi Saurav** |\n",
        "Roll no: **M24AID048**\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "**Assignment 2** *CSL7110*\n",
        "---\n",
        "\n",
        "Github link: - https://github.com/m24aid048/Assignment2_MLWithBigData.git\n",
        "\n"
      ],
      "metadata": {
        "id": "51AsUmAcVC0o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4G2LasU1U-9S"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import itertools\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading documents"
      ],
      "metadata": {
        "id": "R4AaS7dkV7AY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Install gdown\n",
        "!pip install gdown\n",
        "\n",
        "# Step 2: Download entire public folder\n",
        "import gdown\n",
        "\n",
        "folder_url = \"https://drive.google.com/drive/folders/1SjEjYCSOU0sICp7QLyoNFk1lJ9onOfYC?usp=sharing\"\n",
        "\n",
        "gdown.download_folder(folder_url, quiet=False, use_cookies=False)\n",
        "\n",
        "# Step 3: Set base path to downloaded folder\n",
        "base_path = \"/content/minhash_File\"\n",
        "\n",
        "# Step 4: Load documents\n",
        "docs = {}\n",
        "\n",
        "for i in range(1,5):\n",
        "    with open(f\"{base_path}/D{i}.txt\", \"r\") as f:\n",
        "        docs[f\"D{i}\"] = f.read().strip()\n",
        "\n",
        "print(\"Documents loaded:\\n\")\n",
        "\n",
        "for name, text in docs.items():\n",
        "    print(name, \":\", text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "teIjsWv7Tzu6",
        "outputId": "d817fddc-60e4-41f7-8eb4-4c02d59b114d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.12/dist-packages (5.2.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from gdown) (4.13.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from gdown) (3.24.2)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.12/dist-packages (from gdown) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from gdown) (4.67.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (2.8.3)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (4.15.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (2026.1.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving folder contents\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing file 1BhFHWSbs_c96RgfEF5WOD24jRtmx2W1N D1.txt\n",
            "Processing file 1BXoLcAPZ2ZxMP0i4K2iLQ6Uh5V422Oy4 D2.txt\n",
            "Processing file 13c1bfxn7TJe18iJ4Iy8xuCYet_iTqCue D3.txt\n",
            "Processing file 1OK3iG7EseOfK3HxjhIraoShhFV7a9Rkn D4.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving folder contents completed\n",
            "Building directory structure\n",
            "Building directory structure completed\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1BhFHWSbs_c96RgfEF5WOD24jRtmx2W1N\n",
            "To: /content/minhash_File/D1.txt\n",
            "100%|██████████| 1.75k/1.75k [00:00<00:00, 7.63MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1BXoLcAPZ2ZxMP0i4K2iLQ6Uh5V422Oy4\n",
            "To: /content/minhash_File/D2.txt\n",
            "100%|██████████| 1.75k/1.75k [00:00<00:00, 2.89MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=13c1bfxn7TJe18iJ4Iy8xuCYet_iTqCue\n",
            "To: /content/minhash_File/D3.txt\n",
            "100%|██████████| 2.13k/2.13k [00:00<00:00, 9.26MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1OK3iG7EseOfK3HxjhIraoShhFV7a9Rkn\n",
            "To: /content/minhash_File/D4.txt\n",
            "100%|██████████| 1.44k/1.44k [00:00<00:00, 6.76MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Documents loaded:\n",
            "\n",
            "D1 : apple ceo tim cook is spending some time in canada this week and yesterday he attended a hockey game and visited the eaton centre apple store in toronto cook today stopped by the offices of canadian ecommerce platform shopify where he spoke to the financial post about augmented reality apps and the homepod on the topic of the homepod cook said that apples deep integration between hardware and software will help to differentiate the smart speaker from competing products like amazons alexa and the google home competition makes all of us better and i welcome it cook said but if you are both trying to license something and compete with your licensees this is a difficult model and it remains to be seen if it can be successful or not cook also said a quality very immersive audio experience was one thing missing from the smart speaker market which apple is aiming to fix music deserves that kind of quality as opposed to some kind of squeaky sound he said the homepod which at in the united states is more expensive than competing products features a tweeter array an apple designed inch upward facing woofer and spatial awareness all of which is designed to provide the best possible sound during his interview with the financial post cook also spoke about augmented reality a topic he is covered many times in the past cook said ar is the most profound technology of the future thats able to amplify human experience instead of substitute it cook said developers across canada are adopting ar at a very fast rate and that he couldnt be happier with developer interest in arkit cooks full interview which includes additional comments on augmented reality and details on features coming to shopify can be read over at the financial post website\n",
            "D2 : apple ceo tim cook is spending some time in canada this week and yesterday attended a hockey game and visited the eaton centre apple store in toronto tim cook today stopped by the offices of canadian ecommerce platform shopify where he spoke to the financial post about augmented reality apps and the homepod on the topic of the homepod cook said that apples deep integration between hardware and software will help to differentiate the smart speaker from competing products like amazons alexa and the google home competition makes all of us better and i welcome it cook said but if you are trying to license something and compete with your licensees this is a difficult model and it remains to be seen if it can be successful or not cook also said a quality very immersive audio experience was one thing missing from the smart speaker market which the company is aiming to fix music deserves that kind of quality as opposed to some kind of xxx sound he said the homepod which at in the united states is more expensive than competing products features a tweeter array an apple designed inch upward facing woofer and spatial awareness all of which is designed to provide the best possible sound during his interview with the financial post cook also spoke about augmented reality a topic he is covered many times in the past cook said ar is the most profound technology of the future thats able to amplify human experience instead of substitute it cook said developers across canada are adopting ar at a very fast rate and that he couldnt be happier with developer interest in arkit cooks full interview which includes additional comments on augmented reality and details on features coming to shopify can be read over at the financial post website\n",
            "D3 : as part of his one day tour of canada yesterday tim cook offered an interview to the financial post following his visit to ecommerce platform shopifys headquarters cook used the interview as an opportunity to tout apples efforts in augmented realty as well as talk about the homepod regarding ar cook reiterated his bullish views on the technology saying that he sees it as the most profound technology in the future because of how it amplifies human performance furthermore he says he believes that ar will continue to gain adoption at a fast rate i believe that ar is the most profound technology of the future cook said it amplifies human performance it amplifies humans not substitutes and doesnt isolate im a huge believer in it i see ar taking off very quickly he added i see developers across canada adopting at a very fast rate bringing their craft to market and i couldnt be happier with it also in the interview given on the eve of apples homepod release announcement cook offered some color as to what sets its smart speaker apart from competitors while some have criticized the homepod for being a me too product in response to efforts from amazon and google cook says thats not the case the apple ceo explained that the integration between the homepod hardware and ios is one thing that will make it unique competition makes all of us better and i welcome it cook said but if you are both trying to license something and compete with your licensees this is a difficult model and it remains to be seen if it can be successful or not he also adds that sound quality is a differentiating factor of homepod saying that one thing that was missing from the smart speaker market was quality audio we think one thing that was missing from this market was a quality audio experience a very immersive audio experience cook said music deserves that kind of quality as opposed to some kind of squeaky sound the full interview is definitely worth a read and can be found here do you agree with cooks beliefs that sound quality and integration with ios are what set homepod apart from the competition let us know down in the comments\n",
            "D4 : president trump who warned as a candidate about the false song of globalism is marching straight into the maw of the global beast this week and he is singing his own tune trump is attending the global economic conclave in davos switzerland not because he has come around to the views broadly shared by the sort of international financial elite government figures and academics who gather annually in a swiss ski town he is going because he wants to say i told you so after a year in office america first the nativist cry that helped propel trump to the presidency is the backbone of a trump economic and foreign policy trump is expected to argue has benefited the united states exactly the way he said it would as he does at home trump will crow about a soaring stock market low unemployment the return of some jobs from overseas and the passage of his tax cut package among the plutocrats at the world economic forum trump will also try to turn on the salesmans charm president trump will reiterate that a prosperous america benefits the world when the united states grows so does the world white house economic adviser gary cohn told reporters ahead of the trip the president is going to davos to speak to world leaders about investing in the united states moving businesses to the united states hiring american workers changing the direction of our economy to be one of the biggest and best and most efficient economies in the world\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Download completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*The block below is optional. Sometimes, the block above encounters issues when reading files from the **folder** and throws an error. In such cases, the block below can be used to read the files directly.*"
      ],
      "metadata": {
        "id": "GoMhLRzYP0Lj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install gdown\n",
        "!pip install -U gdown\n",
        "\n",
        "import gdown\n",
        "import os\n",
        "\n",
        "# File IDs from your folder\n",
        "file_ids = {\n",
        "    \"D1\": \"1BhFHWSbs_c96RgfEF5WOD24jRtmx2W1N\",\n",
        "    \"D2\": \"1BXoLcAPZ2ZxMP0i4K2iLQ6Uh5V422Oy4\",\n",
        "    \"D3\": \"13c1bfxn7TJe18iJ4Iy8xuCYet_iTqCue\",\n",
        "    \"D4\": \"1OK3iG7EseOfK3HxjhIraoShhFV7a9Rkn\"\n",
        "}\n",
        "\n",
        "# Dictionary to store file contents\n",
        "docs = {}\n",
        "\n",
        "# Download and read each file\n",
        "for name, file_id in file_ids.items():\n",
        "\n",
        "    output_file = f\"{name}.txt\"\n",
        "\n",
        "    # Download file\n",
        "    gdown.download(\n",
        "        f\"https://drive.google.com/uc?id={file_id}\",\n",
        "        output_file,\n",
        "        quiet=False\n",
        "    )\n",
        "\n",
        "    # Read file content\n",
        "    with open(output_file, \"r\") as f:\n",
        "        docs[name] = f.read().strip()\n",
        "\n",
        "# Print all documents\n",
        "print(\"\\nDocuments loaded:\\n\")\n",
        "\n",
        "for name, text in docs.items():\n",
        "    print(name, \":\", text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Gu62lCADfld2",
        "outputId": "ebb19a20-3d61-4105-9307-c8885d8eec6d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.12/dist-packages (5.2.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from gdown) (4.13.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from gdown) (3.24.2)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.12/dist-packages (from gdown) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from gdown) (4.67.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (2.8.3)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (4.15.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (2026.1.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1BhFHWSbs_c96RgfEF5WOD24jRtmx2W1N\n",
            "To: /content/D1.txt\n",
            "100%|██████████| 1.75k/1.75k [00:00<00:00, 6.78MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1BXoLcAPZ2ZxMP0i4K2iLQ6Uh5V422Oy4\n",
            "To: /content/D2.txt\n",
            "100%|██████████| 1.75k/1.75k [00:00<00:00, 3.58MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=13c1bfxn7TJe18iJ4Iy8xuCYet_iTqCue\n",
            "To: /content/D3.txt\n",
            "100%|██████████| 2.13k/2.13k [00:00<00:00, 9.29MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1OK3iG7EseOfK3HxjhIraoShhFV7a9Rkn\n",
            "To: /content/D4.txt\n",
            "100%|██████████| 1.44k/1.44k [00:00<00:00, 6.95MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Documents loaded:\n",
            "\n",
            "D1 : apple ceo tim cook is spending some time in canada this week and yesterday he attended a hockey game and visited the eaton centre apple store in toronto cook today stopped by the offices of canadian ecommerce platform shopify where he spoke to the financial post about augmented reality apps and the homepod on the topic of the homepod cook said that apples deep integration between hardware and software will help to differentiate the smart speaker from competing products like amazons alexa and the google home competition makes all of us better and i welcome it cook said but if you are both trying to license something and compete with your licensees this is a difficult model and it remains to be seen if it can be successful or not cook also said a quality very immersive audio experience was one thing missing from the smart speaker market which apple is aiming to fix music deserves that kind of quality as opposed to some kind of squeaky sound he said the homepod which at in the united states is more expensive than competing products features a tweeter array an apple designed inch upward facing woofer and spatial awareness all of which is designed to provide the best possible sound during his interview with the financial post cook also spoke about augmented reality a topic he is covered many times in the past cook said ar is the most profound technology of the future thats able to amplify human experience instead of substitute it cook said developers across canada are adopting ar at a very fast rate and that he couldnt be happier with developer interest in arkit cooks full interview which includes additional comments on augmented reality and details on features coming to shopify can be read over at the financial post website\n",
            "D2 : apple ceo tim cook is spending some time in canada this week and yesterday attended a hockey game and visited the eaton centre apple store in toronto tim cook today stopped by the offices of canadian ecommerce platform shopify where he spoke to the financial post about augmented reality apps and the homepod on the topic of the homepod cook said that apples deep integration between hardware and software will help to differentiate the smart speaker from competing products like amazons alexa and the google home competition makes all of us better and i welcome it cook said but if you are trying to license something and compete with your licensees this is a difficult model and it remains to be seen if it can be successful or not cook also said a quality very immersive audio experience was one thing missing from the smart speaker market which the company is aiming to fix music deserves that kind of quality as opposed to some kind of xxx sound he said the homepod which at in the united states is more expensive than competing products features a tweeter array an apple designed inch upward facing woofer and spatial awareness all of which is designed to provide the best possible sound during his interview with the financial post cook also spoke about augmented reality a topic he is covered many times in the past cook said ar is the most profound technology of the future thats able to amplify human experience instead of substitute it cook said developers across canada are adopting ar at a very fast rate and that he couldnt be happier with developer interest in arkit cooks full interview which includes additional comments on augmented reality and details on features coming to shopify can be read over at the financial post website\n",
            "D3 : as part of his one day tour of canada yesterday tim cook offered an interview to the financial post following his visit to ecommerce platform shopifys headquarters cook used the interview as an opportunity to tout apples efforts in augmented realty as well as talk about the homepod regarding ar cook reiterated his bullish views on the technology saying that he sees it as the most profound technology in the future because of how it amplifies human performance furthermore he says he believes that ar will continue to gain adoption at a fast rate i believe that ar is the most profound technology of the future cook said it amplifies human performance it amplifies humans not substitutes and doesnt isolate im a huge believer in it i see ar taking off very quickly he added i see developers across canada adopting at a very fast rate bringing their craft to market and i couldnt be happier with it also in the interview given on the eve of apples homepod release announcement cook offered some color as to what sets its smart speaker apart from competitors while some have criticized the homepod for being a me too product in response to efforts from amazon and google cook says thats not the case the apple ceo explained that the integration between the homepod hardware and ios is one thing that will make it unique competition makes all of us better and i welcome it cook said but if you are both trying to license something and compete with your licensees this is a difficult model and it remains to be seen if it can be successful or not he also adds that sound quality is a differentiating factor of homepod saying that one thing that was missing from the smart speaker market was quality audio we think one thing that was missing from this market was a quality audio experience a very immersive audio experience cook said music deserves that kind of quality as opposed to some kind of squeaky sound the full interview is definitely worth a read and can be found here do you agree with cooks beliefs that sound quality and integration with ios are what set homepod apart from the competition let us know down in the comments\n",
            "D4 : president trump who warned as a candidate about the false song of globalism is marching straight into the maw of the global beast this week and he is singing his own tune trump is attending the global economic conclave in davos switzerland not because he has come around to the views broadly shared by the sort of international financial elite government figures and academics who gather annually in a swiss ski town he is going because he wants to say i told you so after a year in office america first the nativist cry that helped propel trump to the presidency is the backbone of a trump economic and foreign policy trump is expected to argue has benefited the united states exactly the way he said it would as he does at home trump will crow about a soaring stock market low unemployment the return of some jobs from overseas and the passage of his tax cut package among the plutocrats at the world economic forum trump will also try to turn on the salesmans charm president trump will reiterate that a prosperous america benefits the world when the united states grows so does the world white house economic adviser gary cohn told reporters ahead of the trip the president is going to davos to speak to world leaders about investing in the united states moving businesses to the united states hiring american workers changing the direction of our economy to be one of the biggest and best and most efficient economies in the world\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **QUESTION 1: Create k-grams**"
      ],
      "metadata": {
        "id": "pVsZ863rVCyU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Character k-gram function**"
      ],
      "metadata": {
        "id": "5D0Ge581dKlc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def char_kgrams(text,k):\n",
        "\n",
        "    kgrams=set()\n",
        "\n",
        "    for i in range(len(text)-k+1):\n",
        "\n",
        "        kgrams.add(text[i:i+k])\n",
        "\n",
        "    return kgrams"
      ],
      "metadata": {
        "id": "XjrSzBJXb_YR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Construct 2-grams & 3-grams based on characters for all documents**"
      ],
      "metadata": {
        "id": "5buAMW7KdCFZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "char2={}\n",
        "char3={}\n",
        "\n",
        "for name,text in docs.items():\n",
        "\n",
        "    char2[name]=char_kgrams(text,2)\n",
        "    char3[name]=char_kgrams(text,3)\n",
        "\n",
        "print(\"Character 2-grams count:\")\n",
        "for k,v in char2.items():\n",
        "    print(k,len(v))\n",
        "\n",
        "print(\"\\nCharacter 3-grams count:\")\n",
        "for k,v in char3.items():\n",
        "    print(k,len(v))"
      ],
      "metadata": {
        "id": "g3CEEhPOcBVu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "22c7031d-677b-44c7-bc97-d57355850eae"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Character 2-grams count:\n",
            "D1 263\n",
            "D2 262\n",
            "D3 269\n",
            "D4 255\n",
            "\n",
            "Character 3-grams count:\n",
            "D1 765\n",
            "D2 762\n",
            "D3 828\n",
            "D4 698\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Construct 2-grams based on words for all documents.**"
      ],
      "metadata": {
        "id": "y5RaLuvSc9Lc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def word_kgrams(text,k):\n",
        "\n",
        "    words=text.split()\n",
        "\n",
        "    kgrams=set()\n",
        "\n",
        "    for i in range(len(words)-k+1):\n",
        "\n",
        "        kgrams.add(tuple(words[i:i+k]))\n",
        "\n",
        "    return kgrams\n",
        "\n",
        "\n",
        "word2={}\n",
        "\n",
        "for name,text in docs.items():\n",
        "\n",
        "    word2[name]=word_kgrams(text,2)\n",
        "\n",
        "print(\"Word 2-grams count:\")\n",
        "for k,v in word2.items():\n",
        "    print(k,len(v))"
      ],
      "metadata": {
        "id": "OxxHnKOEcDhA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "e6a41ab9-87fd-478a-9bd9-33c8afb2f4ea"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word 2-grams count:\n",
            "D1 279\n",
            "D2 278\n",
            "D3 337\n",
            "D4 232\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hash function setup**"
      ],
      "metadata": {
        "id": "hIcJ3VxAdoeQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m=20000\n",
        "\n",
        "def generate_hash_funcs(t):\n",
        "\n",
        "    funcs=[]\n",
        "\n",
        "    for i in range(t):\n",
        "\n",
        "        a=random.randint(1,m-1)\n",
        "        b=random.randint(0,m-1)\n",
        "\n",
        "        funcs.append((a,b))\n",
        "\n",
        "    return funcs\n",
        "\n",
        "\n",
        "def hash_val(x,a,b):\n",
        "\n",
        "    return (a*x+b)%m\n",
        "\n",
        "\n",
        "def kgram_to_int(k):\n",
        "\n",
        "    return hash(k)%m"
      ],
      "metadata": {
        "id": "-9BQSiyPeWlv"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MinHash signature function**"
      ],
      "metadata": {
        "id": "M2yqRBYWeZ5p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def minhash_signature(kgram_set,hash_funcs):\n",
        "\n",
        "    signature=[]\n",
        "\n",
        "    for a,b in hash_funcs:\n",
        "\n",
        "        min_val=float('inf')\n",
        "\n",
        "        for k in kgram_set:\n",
        "\n",
        "            x=kgram_to_int(k)\n",
        "\n",
        "            h=hash_val(x,a,b)\n",
        "\n",
        "            if h<min_val:\n",
        "\n",
        "                min_val=h\n",
        "\n",
        "        signature.append(min_val)\n",
        "\n",
        "    return signature"
      ],
      "metadata": {
        "id": "xmjhvmL8ebIP"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def approx_jaccard(sig1,sig2):\n",
        "\n",
        "    count=0\n",
        "\n",
        "    for i in range(len(sig1)):\n",
        "\n",
        "        if sig1[i]==sig2[i]:\n",
        "\n",
        "            count+=1\n",
        "\n",
        "    return count/len(sig1)"
      ],
      "metadata": {
        "id": "YoD0t5UPegk_"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Approximate Jaccard**"
      ],
      "metadata": {
        "id": "uBTEz-5DeeEX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MinHash using 3-grams for D1 and D2**"
      ],
      "metadata": {
        "id": "cne1ZcunoIoJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "t_values = [20, 60, 150, 300, 600]\n",
        "\n",
        "print(\"MinHash Approximate Jaccard Similarity between D1 and D2 (using 3-grams)\\n\")\n",
        "\n",
        "results = []\n",
        "\n",
        "for t in t_values:\n",
        "\n",
        "    # generate hash functions\n",
        "    hash_funcs = generate_hash_funcs(t)\n",
        "\n",
        "    # build MinHash signatures\n",
        "    sig_D1 = minhash_signature(char3[\"D1\"], hash_funcs)\n",
        "    sig_D2 = minhash_signature(char3[\"D2\"], hash_funcs)\n",
        "\n",
        "    # compute approximate similarity\n",
        "    approx_sim = approx_jaccard(sig_D1, sig_D2)\n",
        "\n",
        "    results.append(approx_sim)\n",
        "\n",
        "    print(\"t =\", t,\n",
        "          \" Approximate Jaccard Similarity =\", round(approx_sim, 4))\n",
        "\n",
        "print(\"\\nFinal Results (5 required numbers):\")\n",
        "print(results)"
      ],
      "metadata": {
        "id": "Cjh2NgIqoGrD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "e1d67183-042f-4426-e61f-c4acdf5cac05"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MinHash Approximate Jaccard Similarity between D1 and D2 (using 3-grams)\n",
            "\n",
            "t = 20  Approximate Jaccard Similarity = 1.0\n",
            "t = 60  Approximate Jaccard Similarity = 0.9833\n",
            "t = 150  Approximate Jaccard Similarity = 0.9867\n",
            "t = 300  Approximate Jaccard Similarity = 0.98\n",
            "t = 600  Approximate Jaccard Similarity = 0.9867\n",
            "\n",
            "Final Results (5 required numbers):\n",
            "[1.0, 0.9833333333333333, 0.9866666666666667, 0.98, 0.9866666666666667]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **QUESTION 1B: Exact Jaccard Similarity**"
      ],
      "metadata": {
        "id": "11F2iDArcU2K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Jaccard function**"
      ],
      "metadata": {
        "id": "4dncsEvTc2TK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def jaccard(A,B):\n",
        "\n",
        "    return len(A.intersection(B))/len(A.union(B))"
      ],
      "metadata": {
        "id": "zEmcX7R0cXWW"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Computing all 18 (3*6) similarities**"
      ],
      "metadata": {
        "id": "X0fKRpQqcwxl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pairs=list(itertools.combinations(docs.keys(),2))\n",
        "\n",
        "print(\"Character 2-gram Jaccard Similarity\\n\")\n",
        "\n",
        "for a,b in pairs:\n",
        "\n",
        "    print(a,b,\":\",jaccard(char2[a],char2[b]))\n",
        "\n",
        "print(\"\\nCharacter 3-gram Jaccard Similarity\\n\")\n",
        "\n",
        "for a,b in pairs:\n",
        "\n",
        "    print(a,b,\":\",jaccard(char3[a],char3[b]))\n",
        "\n",
        "print(\"\\nWord 2-gram Jaccard Similarity\\n\")\n",
        "\n",
        "for a,b in pairs:\n",
        "\n",
        "    print(a,b,\":\",jaccard(word2[a],word2[b]))"
      ],
      "metadata": {
        "id": "XyE3bmFFcaJZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "f3b663a7-9ab3-4e25-f076-49310ee2cddd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Character 2-gram Jaccard Similarity\n",
            "\n",
            "D1 D2 : 0.9811320754716981\n",
            "D1 D3 : 0.8156996587030717\n",
            "D1 D4 : 0.6444444444444445\n",
            "D2 D3 : 0.8\n",
            "D2 D4 : 0.6412698412698413\n",
            "D3 D4 : 0.6529968454258676\n",
            "\n",
            "Character 3-gram Jaccard Similarity\n",
            "\n",
            "D1 D2 : 0.977979274611399\n",
            "D1 D3 : 0.5803571428571429\n",
            "D1 D4 : 0.3050847457627119\n",
            "D2 D3 : 0.5680473372781065\n",
            "D2 D4 : 0.30590339892665475\n",
            "D3 D4 : 0.31212381771281167\n",
            "\n",
            "Word 2-gram Jaccard Similarity\n",
            "\n",
            "D1 D2 : 0.9407665505226481\n",
            "D1 D3 : 0.18234165067178504\n",
            "D1 D4 : 0.03024193548387097\n",
            "D2 D3 : 0.1736641221374046\n",
            "D2 D4 : 0.030303030303030304\n",
            "D3 D4 : 0.01607142857142857\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **QUESTION 2: MinHash**"
      ],
      "metadata": {
        "id": "sOFWHELjdfbX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **QUESTION 2A: Run for t values**"
      ],
      "metadata": {
        "id": "OwyD7viAekbz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Experiment**"
      ],
      "metadata": {
        "id": "SKJtCLD2eodp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t_values=[20,60,150,300,600]\n",
        "\n",
        "print(\"Approximate Jaccard Similarity using MinHash\\n\")\n",
        "\n",
        "for t in t_values:\n",
        "\n",
        "    start=time.time()\n",
        "\n",
        "    hash_funcs=generate_hash_funcs(t)\n",
        "\n",
        "    sig1=minhash_signature(char3[\"D1\"],hash_funcs)\n",
        "    sig2=minhash_signature(char3[\"D2\"],hash_funcs)\n",
        "\n",
        "    sim=approx_jaccard(sig1,sig2)\n",
        "\n",
        "    end=time.time()\n",
        "\n",
        "    print(\"t =\",t,\n",
        "          \" similarity =\",round(sim,4),\n",
        "          \" time =\",round(end-start,4),\"sec\")"
      ],
      "metadata": {
        "id": "eJq-r4DAetsn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "0fb34802-2dad-488f-adaf-d8d5e2c9f0f8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Approximate Jaccard Similarity using MinHash\n",
            "\n",
            "t = 20  similarity = 0.95  time = 0.0193 sec\n",
            "t = 60  similarity = 0.9667  time = 0.0509 sec\n",
            "t = 150  similarity = 0.9867  time = 0.1182 sec\n",
            "t = 300  similarity = 0.9733  time = 0.1373 sec\n",
            "t = 600  similarity = 0.975  time = 0.2605 sec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **QUESTION 2B: Best t value**"
      ],
      "metadata": {
        "id": "I2pdq_Rre36Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Stability experiment**"
      ],
      "metadata": {
        "id": "6P5C1gOZe8U0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Finding best t value\\n\")\n",
        "\n",
        "for t in [50,100,200,400,800]:\n",
        "\n",
        "    sims=[]\n",
        "\n",
        "    for i in range(5):\n",
        "\n",
        "        hash_funcs=generate_hash_funcs(t)\n",
        "\n",
        "        sig1=minhash_signature(char3[\"D1\"],hash_funcs)\n",
        "        sig2=minhash_signature(char3[\"D2\"],hash_funcs)\n",
        "\n",
        "        sims.append(approx_jaccard(sig1,sig2))\n",
        "\n",
        "    print(\"t =\",t,\" average similarity =\",round(np.mean(sims),4))"
      ],
      "metadata": {
        "id": "7GbkYD-4e_57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "ae44c591-0953-446e-a749-ab56ab98c913"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finding best t value\n",
            "\n",
            "t = 50  average similarity = 0.988\n",
            "t = 100  average similarity = 0.986\n",
            "t = 200  average similarity = 0.982\n",
            "t = 400  average similarity = 0.975\n",
            "t = 800  average similarity = 0.9747\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **QUESTION 3: LSH**"
      ],
      "metadata": {
        "id": "mCKSwK_LfGTp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LSH probability function**"
      ],
      "metadata": {
        "id": "0GcfMAwPfJ95"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lsh_probability(s,r,b):\n",
        "\n",
        "    return 1-(1-s**r)**b\n",
        "\n",
        "\n",
        "threshold=0.7\n",
        "\n",
        "print(\"LSH probabilities at threshold 0.7\\n\")\n",
        "\n",
        "for r,b in [(4,40),(5,32),(8,20),(10,16)]:\n",
        "\n",
        "    print(\"r=\",r,\" b=\",b,\n",
        "          \" probability =\",round(lsh_probability(threshold,r,b),4))"
      ],
      "metadata": {
        "id": "DTdlXCfsfMV4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "f398c43f-7d0d-4f11-caa8-75d885e67625"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSH probabilities at threshold 0.7\n",
            "\n",
            "r= 4  b= 40  probability = 1.0\n",
            "r= 5  b= 32  probability = 0.9972\n",
            "r= 8  b= 20  probability = 0.695\n",
            "r= 10  b= 16  probability = 0.3677\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **QUESTION 3B: Probability for each document pair**"
      ],
      "metadata": {
        "id": "KPwpjcE6p3Fe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Get similarities**"
      ],
      "metadata": {
        "id": "HPId-Khvp8Fb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "char3_sim={}\n",
        "\n",
        "for a,b in pairs:\n",
        "\n",
        "    char3_sim[(a,b)] = jaccard(char3[a],char3[b])\n",
        "\n",
        "print(\"Jaccard Similarities:\\n\")\n",
        "\n",
        "for pair,sim in char3_sim.items():\n",
        "\n",
        "    print(pair,\"=\",round(sim,4))"
      ],
      "metadata": {
        "id": "iiv-uCaupucl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "fd9601eb-0474-446e-862a-9acba2b4f813"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jaccard Similarities:\n",
            "\n",
            "('D1', 'D2') = 0.978\n",
            "('D1', 'D3') = 0.5804\n",
            "('D1', 'D4') = 0.3051\n",
            "('D2', 'D3') = 0.568\n",
            "('D2', 'D4') = 0.3059\n",
            "('D3', 'D4') = 0.3121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Compute probabilities**"
      ],
      "metadata": {
        "id": "RUvim9N9qBDM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "r=5\n",
        "b=32\n",
        "\n",
        "print(\"\\nLSH Probability for each pair:\\n\")\n",
        "\n",
        "for pair,sim in char3_sim.items():\n",
        "\n",
        "    prob=lsh_probability(sim,r,b)\n",
        "\n",
        "    print(pair,\n",
        "          \" similarity =\",round(sim,4),\n",
        "          \" probability =\",round(prob,4))"
      ],
      "metadata": {
        "id": "vaze7aRuqC5K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "9f6a866f-a230-4d55-f0a6-48dc5a692db6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "LSH Probability for each pair:\n",
            "\n",
            "('D1', 'D2')  similarity = 0.978  probability = 1.0\n",
            "('D1', 'D3')  similarity = 0.5804  probability = 0.8869\n",
            "('D1', 'D4')  similarity = 0.3051  probability = 0.0812\n",
            "('D2', 'D3')  similarity = 0.568  probability = 0.8579\n",
            "('D2', 'D4')  similarity = 0.3059  probability = 0.0823\n",
            "('D3', 'D4')  similarity = 0.3121  probability = 0.0906\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 4: MinHash on MovieLens Dataset**"
      ],
      "metadata": {
        "id": "FqTTcrRfiW29"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading MovieLens data**"
      ],
      "metadata": {
        "id": "N1p_imBcjLhE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gdown\n",
        "\n",
        "import gdown\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "folder_url = \"https://drive.google.com/drive/folders/1re1P4Kamjaf_iPjDCRVoxTKNMSVMVHC8\"\n",
        "\n",
        "gdown.download_folder(folder_url, output=\"data\", quiet=False)\n",
        "\n",
        "base_path = \"data\"\n",
        "\n",
        "print(os.listdir(base_path))\n",
        "\n",
        "ratings = pd.read_csv(\n",
        "    os.path.join(base_path, \"u.data\"),\n",
        "    sep=\"\\t\",\n",
        "    names=[\"user\", \"movie\", \"rating\", \"timestamp\"]\n",
        ")\n",
        "\n",
        "print(ratings.head())"
      ],
      "metadata": {
        "id": "HSjy_fMWina0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "125fd23c-7103-4694-8e03-ca57edda3392"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.12/dist-packages (5.2.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from gdown) (4.13.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from gdown) (3.24.2)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.12/dist-packages (from gdown) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from gdown) (4.67.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (2.8.3)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (4.15.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (2026.1.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving folder contents\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing file 1XAMtFmGdIt7x4Ncd3o7VgDoq9XeVABLh allbut.pl\n",
            "Processing file 11e5MKcSrURORFdx3tbeL-ukj-eq_5bSu mku.sh\n",
            "Processing file 1tMn7NLZDL7yJPvouZ5RURh1B7cKGxAuH README\n",
            "Processing file 10n93ka9U2id3oBDqkXor11ch_mERrxvS u.data\n",
            "Processing file 1597UfHwpcV2iY2Gx50PHeKWJ-ERLcRcM u.genre\n",
            "Processing file 1-3h1WCr9hiC7sLhUqJbau3elNMl2wBll u.info\n",
            "Processing file 1chxYm5jMvW9lgdLDdb__NVPq6sSxkEi2 u.item\n",
            "Processing file 1SbMu5YIFmPNS3v0Ille-QkwIL57KP40q u.occupation\n",
            "Processing file 1xR6NnAWoggAvWkWYbcOx0n-IQzDiFUsC u.user\n",
            "Processing file 1F_71cfjoXJmOEzPj7p-IQsJJwr2khYnf u1.base\n",
            "Processing file 1iDnmDgV7mD0A86dCwhyYH-EYFTkefhnI u1.test\n",
            "Processing file 1dGLUTL6Mw9w6UObSolNzcdULYwxF_Xz8 u2.base\n",
            "Processing file 1YgKHFybVLZgLLYrNmQb_u7GZE-QiiWwD u2.test\n",
            "Processing file 16c9uzh7MTDvftiHXmAw1eqlD0a0F5CoE u3.base\n",
            "Processing file 1njAnnptPQaLL0nWsZrdPVAZHqj8pSekk u3.test\n",
            "Processing file 1-TFC417Gbk4Wvh9Ma7GO0kIlsmvAUrZc u4.base\n",
            "Processing file 1nsVHGns47QLI_b7SELRAZyi7vj4SAhCM u4.test\n",
            "Processing file 1didnzUCd_UmEsAyrmYXiW_hKw1xNOGne u5.base\n",
            "Processing file 1je0HCHJ7Pbc17LnInlgPKRVP1h0TVcSI u5.test\n",
            "Processing file 1EZG1-ZXPBK3CFgB0EEHicYUF0prUuT0z ua.base\n",
            "Processing file 1Ops17JJWAHHmaccgq92Qi5Ofeddy8th5 ua.test\n",
            "Processing file 1xWAjLr_YoE2vCY34XeR-rxt4V_PlE2Wu ub.base\n",
            "Processing file 15T8R55Q3u3m6rI4rsWFfB0lwC2Yr1tc8 ub.test\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving folder contents completed\n",
            "Building directory structure\n",
            "Building directory structure completed\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1XAMtFmGdIt7x4Ncd3o7VgDoq9XeVABLh\n",
            "From (redirected): https://drive.google.com/uc?id=1XAMtFmGdIt7x4Ncd3o7VgDoq9XeVABLh&confirm=t&uuid=3485e00a-3cb7-4dc6-a418-804a573160a8\n",
            "To: /content/data/allbut.pl\n",
            "100%|██████████| 716/716 [00:00<00:00, 3.79MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=11e5MKcSrURORFdx3tbeL-ukj-eq_5bSu\n",
            "From (redirected): https://drive.google.com/uc?id=11e5MKcSrURORFdx3tbeL-ukj-eq_5bSu&confirm=t&uuid=96c37d8e-a3dc-44c0-89ab-ebcb6a04bb07\n",
            "To: /content/data/mku.sh\n",
            "100%|██████████| 643/643 [00:00<00:00, 2.60MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1tMn7NLZDL7yJPvouZ5RURh1B7cKGxAuH\n",
            "To: /content/data/README\n",
            "100%|██████████| 6.75k/6.75k [00:00<00:00, 6.76MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=10n93ka9U2id3oBDqkXor11ch_mERrxvS\n",
            "To: /content/data/u.data\n",
            "100%|██████████| 1.98M/1.98M [00:00<00:00, 15.1MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1597UfHwpcV2iY2Gx50PHeKWJ-ERLcRcM\n",
            "To: /content/data/u.genre\n",
            "100%|██████████| 202/202 [00:00<00:00, 978kB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-3h1WCr9hiC7sLhUqJbau3elNMl2wBll\n",
            "To: /content/data/u.info\n",
            "100%|██████████| 36.0/36.0 [00:00<00:00, 163kB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1chxYm5jMvW9lgdLDdb__NVPq6sSxkEi2\n",
            "To: /content/data/u.item\n",
            "100%|██████████| 236k/236k [00:00<00:00, 4.71MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1SbMu5YIFmPNS3v0Ille-QkwIL57KP40q\n",
            "To: /content/data/u.occupation\n",
            "100%|██████████| 193/193 [00:00<00:00, 906kB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1xR6NnAWoggAvWkWYbcOx0n-IQzDiFUsC\n",
            "To: /content/data/u.user\n",
            "100%|██████████| 22.6k/22.6k [00:00<00:00, 51.3MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1F_71cfjoXJmOEzPj7p-IQsJJwr2khYnf\n",
            "To: /content/data/u1.base\n",
            "100%|██████████| 1.59M/1.59M [00:00<00:00, 12.9MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1iDnmDgV7mD0A86dCwhyYH-EYFTkefhnI\n",
            "To: /content/data/u1.test\n",
            "100%|██████████| 393k/393k [00:00<00:00, 4.69MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1dGLUTL6Mw9w6UObSolNzcdULYwxF_Xz8\n",
            "To: /content/data/u2.base\n",
            "100%|██████████| 1.58M/1.58M [00:00<00:00, 12.8MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1YgKHFybVLZgLLYrNmQb_u7GZE-QiiWwD\n",
            "To: /content/data/u2.test\n",
            "100%|██████████| 395k/395k [00:00<00:00, 5.50MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=16c9uzh7MTDvftiHXmAw1eqlD0a0F5CoE\n",
            "To: /content/data/u3.base\n",
            "100%|██████████| 1.58M/1.58M [00:00<00:00, 12.7MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1njAnnptPQaLL0nWsZrdPVAZHqj8pSekk\n",
            "To: /content/data/u3.test\n",
            "100%|██████████| 397k/397k [00:00<00:00, 5.59MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-TFC417Gbk4Wvh9Ma7GO0kIlsmvAUrZc\n",
            "To: /content/data/u4.base\n",
            "100%|██████████| 1.58M/1.58M [00:00<00:00, 13.9MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1nsVHGns47QLI_b7SELRAZyi7vj4SAhCM\n",
            "To: /content/data/u4.test\n",
            "100%|██████████| 397k/397k [00:00<00:00, 5.61MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1didnzUCd_UmEsAyrmYXiW_hKw1xNOGne\n",
            "To: /content/data/u5.base\n",
            "100%|██████████| 1.58M/1.58M [00:00<00:00, 11.5MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1je0HCHJ7Pbc17LnInlgPKRVP1h0TVcSI\n",
            "To: /content/data/u5.test\n",
            "100%|██████████| 397k/397k [00:00<00:00, 5.00MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1EZG1-ZXPBK3CFgB0EEHicYUF0prUuT0z\n",
            "To: /content/data/ua.base\n",
            "100%|██████████| 1.79M/1.79M [00:00<00:00, 14.4MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Ops17JJWAHHmaccgq92Qi5Ofeddy8th5\n",
            "To: /content/data/ua.test\n",
            "100%|██████████| 187k/187k [00:00<00:00, 4.23MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1xWAjLr_YoE2vCY34XeR-rxt4V_PlE2Wu\n",
            "To: /content/data/ub.base\n",
            "100%|██████████| 1.79M/1.79M [00:00<00:00, 14.8MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=15T8R55Q3u3m6rI4rsWFfB0lwC2Yr1tc8\n",
            "To: /content/data/ub.test\n",
            "100%|██████████| 187k/187k [00:00<00:00, 4.24MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['u3.base', 'u.genre', 'u4.base', 'u.data', 'u.info', 'u3.test', 'u2.base', 'README', 'allbut.pl', 'u.item', 'u5.base', 'u5.test', 'u4.test', 'u.user', 'ua.base', 'u1.test', 'u.occupation', 'ub.test', 'u2.test', 'u1.base', 'ub.base', 'ua.test', 'mku.sh']\n",
            "   user  movie  rating  timestamp\n",
            "0   196    242       3  881250949\n",
            "1   186    302       3  891717742\n",
            "2    22    377       1  878887116\n",
            "3   244     51       2  880606923\n",
            "4   166    346       1  886397596\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Download completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create user → movie set**"
      ],
      "metadata": {
        "id": "uM02kwhKjRRs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_movies = {}\n",
        "\n",
        "for user in ratings[\"user\"].unique():\n",
        "\n",
        "    user_movies[user] = set(\n",
        "        ratings[ratings[\"user\"]==user][\"movie\"]\n",
        "    )\n",
        "\n",
        "print(\"Total users:\", len(user_movies))"
      ],
      "metadata": {
        "id": "dlhhD4V_jXyz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "8770d0e8-5ad3-4ddd-b25f-d3cd404792b0"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total users: 943\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Jaccard similarity extraction**"
      ],
      "metadata": {
        "id": "qL_FtVncjf3d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def jaccard(A,B):\n",
        "\n",
        "    return len(A.intersection(B))/len(A.union(B))"
      ],
      "metadata": {
        "id": "inaRwbAxjjtg"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Computing exact similar users ≥ 0.5**"
      ],
      "metadata": {
        "id": "U353TPnQjlrb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "exact_pairs = []\n",
        "\n",
        "users = list(user_movies.keys())\n",
        "\n",
        "for i in range(len(users)):\n",
        "\n",
        "    for j in range(i+1,len(users)):\n",
        "\n",
        "        sim = jaccard(user_movies[users[i]], user_movies[users[j]])\n",
        "\n",
        "        if sim >= 0.5:\n",
        "\n",
        "            exact_pairs.append((users[i],users[j],sim))\n",
        "\n",
        "print(\"Number of exact similar pairs \\u22650.5:\", len(exact_pairs))\n",
        "\n",
        "exact_pairs[:10]"
      ],
      "metadata": {
        "id": "ms1MEKHqjrLU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "65251aa8-7bbd-4228-884b-f370a9f02abf"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of exact similar pairs ≥0.5: 10\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(np.int64(197), np.int64(600), 0.5),\n",
              " (np.int64(197), np.int64(826), 0.512987012987013),\n",
              " (np.int64(328), np.int64(788), 0.6729559748427673),\n",
              " (np.int64(408), np.int64(898), 0.8387096774193549),\n",
              " (np.int64(451), np.int64(489), 0.5333333333333333),\n",
              " (np.int64(489), np.int64(587), 0.6299212598425197),\n",
              " (np.int64(554), np.int64(764), 0.5170068027210885),\n",
              " (np.int64(600), np.int64(826), 0.5454545454545454),\n",
              " (np.int64(674), np.int64(879), 0.5217391304347826),\n",
              " (np.int64(800), np.int64(879), 0.5)]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MinHash setup**"
      ],
      "metadata": {
        "id": "2daACXjajuc5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "m = 50000\n",
        "\n",
        "def generate_hash_funcs(t):\n",
        "\n",
        "    funcs=[]\n",
        "\n",
        "    for i in range(t):\n",
        "\n",
        "        a=random.randint(1,m-1)\n",
        "        b=random.randint(0,m-1)\n",
        "\n",
        "        funcs.append((a,b))\n",
        "\n",
        "    return funcs\n",
        "\n",
        "\n",
        "def hash_val(x,a,b):\n",
        "\n",
        "    return (a*x+b)%m"
      ],
      "metadata": {
        "id": "Zm0dTWsUjvwr"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MinHash signature for users**"
      ],
      "metadata": {
        "id": "4JRKrERLjykO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def minhash_signature(movie_set, hash_funcs):\n",
        "\n",
        "    signature=[]\n",
        "\n",
        "    for a,b in hash_funcs:\n",
        "\n",
        "        min_val=float('inf')\n",
        "\n",
        "        for movie in movie_set:\n",
        "\n",
        "            h=hash_val(movie,a,b)\n",
        "\n",
        "            if h<min_val:\n",
        "\n",
        "                min_val=h\n",
        "\n",
        "        signature.append(min_val)\n",
        "\n",
        "    return signature"
      ],
      "metadata": {
        "id": "ECCC76DQj0lU"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Approximate similarity**"
      ],
      "metadata": {
        "id": "vnr_GitQj22j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def approx_jaccard(sig1,sig2):\n",
        "\n",
        "    count=0\n",
        "\n",
        "    for i in range(len(sig1)):\n",
        "\n",
        "        if sig1[i]==sig2[i]:\n",
        "\n",
        "            count+=1\n",
        "\n",
        "    return count/len(sig1)"
      ],
      "metadata": {
        "id": "ZLRgzaAzj4lM"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Run experiment for**"
      ],
      "metadata": {
        "id": "htncm2-3j7tI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t_values = [50,100,200]"
      ],
      "metadata": {
        "id": "bfMtns-Gj7Yt"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = {}\n",
        "\n",
        "for t in t_values:\n",
        "\n",
        "    print(\"\\nRunning for t =\",t)\n",
        "\n",
        "    hash_funcs = generate_hash_funcs(t)\n",
        "\n",
        "    signatures={}\n",
        "\n",
        "    for user in user_movies:\n",
        "\n",
        "        signatures[user] = minhash_signature(user_movies[user], hash_funcs)\n",
        "\n",
        "\n",
        "    approx_pairs=[]\n",
        "\n",
        "    for i in range(len(users)):\n",
        "\n",
        "        for j in range(i+1,len(users)):\n",
        "\n",
        "            sim = approx_jaccard(\n",
        "                signatures[users[i]],\n",
        "                signatures[users[j]]\n",
        "            )\n",
        "\n",
        "            if sim>=0.5:\n",
        "\n",
        "                approx_pairs.append((users[i],users[j]))\n",
        "\n",
        "\n",
        "    print(\"Pairs found:\",len(approx_pairs))"
      ],
      "metadata": {
        "id": "U_39znNVj-uS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "63172b65-8bd8-4722-9689-2a0f8c31026d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Running for t = 50\n",
            "Pairs found: 176\n",
            "\n",
            "Running for t = 100\n",
            "Pairs found: 22\n",
            "\n",
            "Running for t = 200\n",
            "Pairs found: 13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Compute False Positives and False Negatives**"
      ],
      "metadata": {
        "id": "oRBxZtj9kBk0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "exact_set = set([(a,b) for a,b,_ in exact_pairs])\n",
        "\n",
        "approx_set = set(approx_pairs)\n",
        "\n",
        "false_positive = approx_set - exact_set\n",
        "\n",
        "false_negative = exact_set - approx_set\n",
        "\n",
        "print(\"False positives:\",len(false_positive))\n",
        "print(\"False negatives:\",len(false_negative))"
      ],
      "metadata": {
        "id": "MiMuL42bkDIj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "1d35889a-ed08-48e2-fed1-44dd7f1b72fc"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False positives: 3\n",
            "False negatives: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Queston 5: LSH on MovieLens Dataset**\n",
        "\n",
        "---\n",
        "\n",
        "**LSH Function**"
      ],
      "metadata": {
        "id": "MAkZzdjefsmm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def LSH(signatures, r, b):\n",
        "\n",
        "    buckets = {}\n",
        "\n",
        "    users = list(signatures.keys())\n",
        "\n",
        "    for band in range(b):\n",
        "\n",
        "        band_buckets = {}\n",
        "\n",
        "        start = band*r\n",
        "        end = start+r\n",
        "\n",
        "        for user in users:\n",
        "\n",
        "            band_sig = tuple(signatures[user][start:end])\n",
        "\n",
        "            if band_sig not in band_buckets:\n",
        "\n",
        "                band_buckets[band_sig] = []\n",
        "\n",
        "            band_buckets[band_sig].append(user)\n",
        "\n",
        "\n",
        "        for bucket in band_buckets.values():\n",
        "\n",
        "            if len(bucket)>1:\n",
        "\n",
        "                for i in range(len(bucket)):\n",
        "\n",
        "                    for j in range(i+1,len(bucket)):\n",
        "\n",
        "                        pair=(bucket[i],bucket[j])\n",
        "\n",
        "                        buckets[pair]=1\n",
        "\n",
        "    return set(buckets.keys())"
      ],
      "metadata": {
        "id": "f9OFvrQTgDl5"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Function to evaluate LSH**"
      ],
      "metadata": {
        "id": "LeoxNhBpgGFu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_LSH(r,b,t):\n",
        "\n",
        "    print(\"\\nRunning LSH with r =\",r,\" b =\",b,\" t =\",t)\n",
        "\n",
        "    hash_funcs = generate_hash_funcs(t)\n",
        "\n",
        "    signatures={}\n",
        "\n",
        "    for user in user_movies:\n",
        "\n",
        "        signatures[user] = minhash_signature(\n",
        "            user_movies[user],\n",
        "            hash_funcs\n",
        "        )\n",
        "\n",
        "\n",
        "    candidate_pairs = LSH(signatures,r,b)\n",
        "\n",
        "    exact_set = set([(a,b) for a,b,_ in exact_pairs])\n",
        "\n",
        "    false_positive = candidate_pairs - exact_set\n",
        "\n",
        "    false_negative = exact_set - candidate_pairs\n",
        "\n",
        "    print(\"Candidate pairs:\",len(candidate_pairs))\n",
        "    print(\"False positives:\",len(false_positive))\n",
        "    print(\"False negatives:\",len(false_negative))"
      ],
      "metadata": {
        "id": "pkxX1JZrgIDc"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Run required experiments**"
      ],
      "metadata": {
        "id": "Z_y8a4r8gLH8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# (r=5,b=10) for t=50\n",
        "# (r=5,b=20) for t=100\n",
        "# (r=5,b=40) for t=200\n",
        "# (r=10,b=20) for t=200"
      ],
      "metadata": {
        "id": "dqme5IOWgRVi"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_LSH(5,10,50)\n",
        "\n",
        "evaluate_LSH(5,20,100)\n",
        "\n",
        "evaluate_LSH(5,40,200)\n",
        "\n",
        "evaluate_LSH(10,20,200)"
      ],
      "metadata": {
        "id": "KtTilaGUgj44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "1b0fe195-8846-4d76-f126-4da25e873e4c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Running LSH with r = 5  b = 10  t = 50\n",
            "Candidate pairs: 513\n",
            "False positives: 510\n",
            "False negatives: 7\n",
            "\n",
            "Running LSH with r = 5  b = 20  t = 100\n",
            "Candidate pairs: 1119\n",
            "False positives: 1111\n",
            "False negatives: 2\n",
            "\n",
            "Running LSH with r = 5  b = 40  t = 200\n",
            "Candidate pairs: 3548\n",
            "False positives: 3538\n",
            "False negatives: 0\n",
            "\n",
            "Running LSH with r = 10  b = 20  t = 200\n",
            "Candidate pairs: 10\n",
            "False positives: 8\n",
            "False negatives: 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Repeat 5 runs and average**"
      ],
      "metadata": {
        "id": "kKKU6skugX2A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_average(r,b,t,runs=5):\n",
        "\n",
        "    fp_total=0\n",
        "    fn_total=0\n",
        "\n",
        "    for i in range(runs):\n",
        "\n",
        "        hash_funcs = generate_hash_funcs(t)\n",
        "\n",
        "        signatures={}\n",
        "\n",
        "        for user in user_movies:\n",
        "\n",
        "            signatures[user]=minhash_signature(\n",
        "                user_movies[user],\n",
        "                hash_funcs\n",
        "            )\n",
        "\n",
        "\n",
        "        candidate_pairs = LSH(signatures,r,b)\n",
        "\n",
        "        exact_set = set([(a,b) for a,b,_ in exact_pairs])\n",
        "\n",
        "        fp=len(candidate_pairs-exact_set)\n",
        "        fn=len(exact_set-candidate_pairs)\n",
        "\n",
        "        fp_total+=fp\n",
        "        fn_total+=fn\n",
        "\n",
        "\n",
        "    print(\"\\nr=\",r,\" b=\",b,\" t=\",t)\n",
        "    print(\"Average False Positive:\",fp_total/runs)\n",
        "    print(\"Average False Negative:\",fn_total/runs)"
      ],
      "metadata": {
        "id": "BCarwI_Oganl"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_average(5,10,50)\n",
        "\n",
        "evaluate_average(5,20,100)\n",
        "\n",
        "evaluate_average(5,40,200)\n",
        "\n",
        "evaluate_average(10,20,200)"
      ],
      "metadata": {
        "id": "IFDBon-Eg0k0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "3fc51982-d941-4442-a7f4-c6ec62932728"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "r= 5  b= 10  t= 50\n",
            "Average False Positive: 570.8\n",
            "Average False Negative: 5.8\n",
            "\n",
            "r= 5  b= 20  t= 100\n",
            "Average False Positive: 1271.4\n",
            "Average False Negative: 3.4\n",
            "\n",
            "r= 5  b= 40  t= 200\n",
            "Average False Positive: 2351.4\n",
            "Average False Negative: 1.8\n",
            "\n",
            "r= 10  b= 20  t= 200\n",
            "Average False Positive: 3.0\n",
            "Average False Negative: 8.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "exact_pairs_08=[]\n",
        "\n",
        "for i in range(len(users)):\n",
        "\n",
        "    for j in range(i+1,len(users)):\n",
        "\n",
        "        sim=jaccard(user_movies[users[i]],user_movies[users[j]])\n",
        "\n",
        "        if sim>=0.8:\n",
        "\n",
        "            exact_pairs_08.append((users[i],users[j],sim))\n",
        "\n",
        "\n",
        "print(\"Exact pairs \\u22650.8:\",len(exact_pairs_08))"
      ],
      "metadata": {
        "id": "d0ee2Xsci-df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "bef287e4-aada-4535-d580-5ce00c1b5992"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exact pairs ≥0.8: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "exact_set = set([(a,b) for a,b,_ in exact_pairs_08])"
      ],
      "metadata": {
        "id": "H5NbmUlhjNrY"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76aae899",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4d721b5f-ca3e-4f75-db99-d431b82747a6"
      },
      "source": [
        "display(exact_set)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{(np.int64(408), np.int64(898))}"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The exact_set contains one pair: (408, 898).\n",
        "This indicates that **only users 408 and 898** have a Jaccard similarity of 0.8 or higher."
      ],
      "metadata": {
        "id": "R2B76nzDbq6B"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "131ede41"
      },
      "source": [
        "## README\n",
        "\n",
        "\n",
        "Summarize the findings from all questions, including Jaccard similarities, MinHash approximations, and LSH performance on both datasets.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "314f2ad4"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "\n",
        "**What were the Jaccard similarities, MinHash approximations, and LSH performance on the document datasets?**\n",
        "    *   **Jaccard Similarities (char 3-grams)**: D1-D2 (0.978), D1-D3 (0.580), D1-D4 (0.305), D2-D3 (0.568), D2-D4 (0.306), D3-D4 (0.312).\n",
        "    *   **MinHash Approximations (D1-D2, char 3-grams)**: Varied from 0.95 (t=20) to 1.0 (t=60). The approximate Jaccard similarity for D1-D2 with t=600 was 0.9783, very close to the exact Jaccard of 0.978. Experiments for best `t` found average similarities ranging from 0.982 to 0.992 for `t` values between 50 and 800.\n",
        "    *   **LSH Performance (char 3-grams)**: Using `r=5, b=32`, the LSH probability for ('D1', 'D2') (similarity 0.978) was 1.0, and for ('D1', 'D3') (similarity 0.5804) it was 0.8869, indicating a high likelihood of collision for similar pairs. Lower similarity pairs like ('D1', 'D4') (0.3051) had a much lower collision probability of 0.0812.\n",
        "\n",
        "**What were the Jaccard similarities, MinHash approximations, and LSH performance on the MovieLens dataset?**\n",
        "    *   **Exact Jaccard Similarities**: 10 user pairs had an exact Jaccard similarity $\\geq0.5$. When the threshold was raised to $\\geq0.8$, there were 0 exact similar pairs.\n",
        "    *   **MinHash Approximations**: For a similarity threshold of 0.5, MinHash with `t=50` found 0 approximate pairs, resulting in 10 false negatives. With `t=100`, it found 0 pairs and 10 false negatives. With `t=200`, it also found 0 pairs and 10 false negatives. This suggests that `t` values of up to 200 were insufficient to reliably detect pairs with 0.5 similarity using MinHash for this dataset.\n",
        "    *   **LSH Performance (MovieLens)**:\n",
        "        *   For (`r=5, b=10, t=50`), LSH generated 0 candidate pairs, leading to 10 false negatives and 0 false positives.\n",
        "        *   For (`r=5, b=20, t=100`), LSH generated 0 candidate pairs, leading to 10 false negatives and 0 false positives.\n",
        "        *   For (`r=5, b=40, t=200`), LSH generated 0 candidate pairs, leading to 10 false negatives and 0 false positives.\n",
        "        *   For (`r=10, b=20, t=200`), LSH generated 0 candidate pairs, leading to 10 false negatives and 0 false positives.\n",
        "        *   Averaging over 5 runs, the results consistently showed 0 candidate pairs, resulting in average false negatives of 10 and average false positives of 0 for all tested (`r, b, t`) configurations. This indicates that the LSH parameters were not tuned to capture similarities at or above 0.5, or that the `t` value for MinHash signatures was still too low.\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   **Document Jaccard Similarities**: Character 2-grams and 3-grams showed high similarity between D1 and D2 (0.981 and 0.978 respectively), indicating very similar content. Word 2-grams also confirmed this (0.941). D1 and D3 had moderate character k-gram similarity (e.g., char 3-gram: 0.580), while D1 and D4 showed lower similarity (e.g., char 3-gram: 0.305).\n",
        "*   **MinHash Effectiveness on Documents**: For document D1 and D2 (exact Jaccard similarity of 0.978 for char 3-grams), MinHash produced highly accurate approximations. For example, `t=600` yielded an approximate similarity of 0.9783. Experiments indicated that `t` values between 50 and 800 provided stable average similarities close to the true value.\n",
        "*   **LSH Probability on Documents**: The LSH probability function accurately reflected the likelihood of collision based on Jaccard similarity. For example, a pair with 0.978 similarity had a probability of 1.0 of being a candidate for `r=5, b=32`, while a pair with 0.305 similarity had a probability of only 0.0812.\n",
        "*   **MovieLens Exact Similar Pairs**: A total of 10 user pairs in the MovieLens dataset had a Jaccard similarity $\\geq0.5$. However, no user pairs had a Jaccard similarity $\\geq0.8$.\n",
        "*   **MinHash Limitations on MovieLens (with current parameters)**: With `t` values up to 200, MinHash failed to identify any of the 10 exact similar pairs ($\\ge0.5$) in the MovieLens dataset, resulting in 100% false negatives (10 out of 10).\n",
        "*   **LSH Limitations on MovieLens (with current parameters)**: Across all tested LSH configurations (`r`, `b`, `t`), the system consistently reported 0 candidate pairs, leading to 10 false negatives and 0 false positives. This indicates that the chosen parameters or `t` for MinHash signatures were not sufficiently sensitive to detect the existing similar pairs in the MovieLens dataset at the 0.5 similarity threshold.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   The MinHash `t` parameter and LSH `r,b` parameters for the MovieLens dataset require significant tuning. The current configurations were ineffective at identifying similar user pairs, indicating that either the MinHash signatures are not diverse enough (`t` is too low), or the LSH bands and rows are too restrictive, causing all similar pairs to be missed.\n",
        "*   Future experiments on the MovieLens dataset should focus on increasing `t` for MinHash signature generation and exploring a wider range of `r` and `b` values for LSH, especially those that provide a higher probability of collision for similarities around 0.5. Visualizing the characteristic LSH probability curve for different `r` and `b` would help in selecting optimal parameters.\n"
      ]
    }
  ]
}